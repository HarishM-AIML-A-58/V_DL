# ğŸ§  Deep Learning Laboratory â€” AI23531
**Course Code:** AI23531 | **Semester:** V | **Academic Year:** 2025â€“2026  
**Author:** Harish M (Reg. No. 2116-231501058)  
**Institution:** Rajalakshmi Engineering College, Chennai  

---

## ğŸ“‹ Table of Contents
| Section | Description |
|----------|-------------|
| [ğŸ“˜ Introduction](#-introduction) | Overview of the Deep Learning Lab |
| [ğŸ§© Experiments Overview](#-experiments-overview) | Summary of all experiments |
| [âš™ï¸ Technologies Used](#ï¸-technologies-used) | Tools, frameworks, and environments |
| [ğŸ“Š Experiment Details](#-experiment-details) | Detailed objectives and implementation overview |
| [ğŸš€ Key Concepts](#-key-concepts) | Core learning takeaways |
| [ğŸ“‚ Repository Structure](#-repository-structure) | Organized layout of experiments |
| [ğŸ Conclusion](#-conclusion) | Final summary |
| [ğŸ‘¨â€ğŸ’» Author](#-author) | Author details |

---

## ğŸ“˜ Introduction

This repository documents the **Deep Learning Laboratory (AI23531)** conducted during the fifth semester of the B.Tech AIML program.  
It contains a collection of experiments implemented using **TensorFlow, Keras, and PyTorch**, covering essential topics such as CNNs, RNNs, GANs, and optimization techniques.  

Each experiment is designed to **bridge theory and application**, providing an end-to-end understanding of model development, evaluation, and visualization.

---

## ğŸ§© Experiments Overview

| Exp No. | Title | Date | Key Concepts |
|----------|--------|------|--------------|
| 1 | Handwritten Digit Recognition using Neural Network | 19-07-2025 | Neural Networks, MNIST |
| 2 | Multi-Layer Perceptron | 02-08-2025 | MLP, Activation Functions |
| 3 | SGD with Momentum vs Adam Optimizer | 30-08-2025 | Optimizers, PyTorch |
| 4 | Implement CNN from Scratch | 06-09-2025 | Convolutional Layers, CIFAR-10 |
| 5 | Image Classification using VGGNet, ResNet & GoogLeNet | 06-09-2025 | Transfer Learning, Pretrained Models |
| 6 | BRNN vs FFNN | 13-09-2025 | Sequential Modeling, LSTM |
| 7 | Caption Generation using RNN + CNN | 20-09-2025 | Encoder-Decoder, Multimodal DL |
| 8 | Image Generation using VAE | 27-09-2025 | Latent Space Learning, Autoencoders |
| 9 | Text Generation using LSTM | 04-10-2025 | NLP, Sequence Modeling |
| 10 | Generative Adversarial Networks | 11-10-2025 | GANs, Image Synthesis |

---

## âš™ï¸ Technologies Used

| Category | Tools |
|-----------|-------|
| Programming Languages | Python 3.11 |
| Frameworks | TensorFlow, PyTorch, Keras |
| Supporting Libraries | NumPy, Matplotlib, Pandas, Seaborn |
| Datasets | MNIST, CIFAR-10, CelebA, Cats vs Dogs, Shakespeare Corpus |
| Deployment & Visualization | Google Colab, Jupyter Notebook, Matplotlib |
| Environment | GPU Accelerated (CUDA enabled) |

---

## ğŸ“Š Experiment Details

### 1ï¸âƒ£ Handwritten Digit Recognition
- **Dataset:** MNIST  
- **Concepts:** Forward & Backpropagation, ReLU, Softmax  
- **Accuracy:** 97%  

### 2ï¸âƒ£ Multi-Layer Perceptron (MLP)
- **Dataset:** Iris  
- **Concepts:** Multi-class classification, Activation tuning  
- **Accuracy:** 98%  

### 3ï¸âƒ£ SGD with Momentum vs Adam
- **Dataset:** CIFAR-10  
- **Concepts:** Optimizer comparison, Learning curves  
- **Result:** Adam achieved higher accuracy (72.78%) and faster convergence.

### 4ï¸âƒ£ CNN from Scratch
- **Dataset:** CIFAR-10  
- **Architecture:** Conv2D â†’ Pooling â†’ Fully Connected  
- **Accuracy:** 72%  

### 5ï¸âƒ£ Transfer Learning: VGG16, ResNet50, InceptionV3
- **Dataset:** Cats vs Dogs  
- **Result:** InceptionV3 performed best with 97.63% validation accuracy.

### 6ï¸âƒ£ BRNN vs FFNN
- **Dataset:** Airline Passenger Data  
- **Result:** FFNN outperformed BRNN for short-term prediction tasks.

### 7ï¸âƒ£ Caption Generation using RNN + CNN
- **Dataset:** MS COCO / Flickr8k  
- **Concepts:** Encoder-Decoder Model  
- **Outcome:** Generated meaningful captions.

### 8ï¸âƒ£ Image Generation using VAE
- **Dataset:** CelebA / CIFAR-10  
- **Concepts:** Latent Space Sampling, KL Divergence  
- **Outcome:** Generated realistic samples.

### 9ï¸âƒ£ Text Generation using LSTM
- **Dataset:** Shakespeare Corpus  
- **Concepts:** Character-level text modeling  
- **Outcome:** Generated Shakespeare-style sequences.

### ğŸ”Ÿ Generative Adversarial Network
- **Dataset:** FashionMNIST  
- **Concepts:** Adversarial Training, Image Synthesis  
- **Outcome:** GAN produced realistic fashion images.

---

## ğŸš€ Key Concepts

| Area | Core Idea |
|-------|------------|
| Neural Networks | Feedforward computation and backpropagation |
| Optimization | Momentum, Adam, Learning Rate Scheduling |
| CNN Architectures | Feature extraction and deep representation |
| RNN & LSTM | Temporal sequence learning |
| Generative Models | Autoencoders, VAEs, GANs |
| Transfer Learning | Using pretrained architectures |
| Evaluation Metrics | Accuracy, MSE, RMSE, FID, Loss Curves |

---

## ğŸ“‚ Repository Structure
```
ğŸ“¦ DeepLearning-Lab
 â”£ ğŸ“‚ Exp01_Handwritten_Digit_Recognition/
 â”£ ğŸ“‚ Exp02_MLP/
 â”£ ğŸ“‚ Exp03_SGD_vs_Adam/
 â”£ ğŸ“‚ Exp04_CNN_Scratch/
 â”£ ğŸ“‚ Exp05_VGG_ResNet_Inception/
 â”£ ğŸ“‚ Exp06_BRNN_vs_FFNN/
 â”£ ğŸ“‚ Exp07_Caption_Generation/
 â”£ ğŸ“‚ Exp08_VAE_Image_Generation/
 â”£ ğŸ“‚ Exp09_Text_Generation_LSTM/
 â”£ ğŸ“‚ Exp10_GAN/
 â”£ ğŸ“œ requirements.txt
 â”£ ğŸ“œ README.md
 â”— ğŸ“œ LICENSE
```

---

## ğŸ Conclusion
This repository serves as a **comprehensive portfolio of deep learning fundamentals and applications** â€” from classical neural networks to advanced generative models.  
It demonstrates hands-on understanding of **model design, training, optimization, and deployment**, using industry-standard frameworks and datasets.

---

## ğŸ‘¨â€ğŸ’» Author
**Name:** Harish M  
**Register Number:** 2116-231501058  
**Course:** B.Tech AIML â€“ 3rd Year  
**Institution:** Rajalakshmi Engineering College  
ğŸ“§ harishm@email.com  
ğŸŒ [GitHub Profile](https://github.com/harishm)
